\section*{Implementation}

For each hash function we established a standard model for implementation: each hash function has internal {\tt Init}, {\tt Update}, and {\tt Final} function.
Each of these functions was converted to an OpenCL kernel we wrote a wrapper in Python using the PyOpenCL library to implement our evaluation methodology.
Specific implementation details and roadblocks encountered follow.

\subsection*{SHA-1 \& OpenCL}

As a reference, we decided to implement a current NIST standard, SHA-1 so that we could get some familiarity with the OpenCL framework.
SHA-1 is a reasonably straight forward algorithm with many reference implementations floating around.
We took one and modified it to work in the OpenCL framework.

Not surprisingly, even though OpenCL is a variant of C99, modifying code to run on OpenCL devices is difficult.
As far as we know, there are no debuggers and getting output when running on the GPU is difficult as there are no facilities for logging.
We thus had to resort to reading buffers with specially crafted debug output in so that we could compare the state of the algorithms to the reference state on the CPU.

Often times our implementations simply would not build for the target platform without any indication as to why.
We often had to resort to commenting out large sections of code until it will build and slowly trying the offending line of code.
Mostly, the problem had to do with pieces of code accessing regions of memory that they were not supposed to.
OpenCL's memory model consists of private, local and global; and a region of memory can only access that region it has be specified for.
Thus a region marked global cannot be accessed by a private variable.
Getting code to compile was difficult enough, but getting to run on the GPU when it would run fine on the CPU was an even more laborious process.

\subsection*{CubeHash}

CubeHash's optimized reference implementation was relatively simple to get working in OpenCL.
However, because this was the first SHA-3 algorithm we implemented to work on OpenCL we learned a lot about how we should structure our code.
In the beginning we decided to create one monolithic {\tt Hash} function that contained all the necessary logic to return a hash for an arbitrary message.
This proved to be inefficient when the messages started becoming large because we had to allocate exactly as many bytes on the device as the length of the message.
We immediately noticed that most of our algorithms could not run beyond 16KB which happened to be the local memory size.

Thus we decided to change our implementations to use the standard {\tt Init}, {\tt Update} and {\tt Final} functions to support large messages.
With this design we would only have to maintain a fixed amount of bytes for the algorithm's state along with a fixed amount of bytes for the input to the {\tt Update} function.
By splitting up the message into smaller parts, we could sequentially feed them to {\tt Update}.
Once we fed all of the messages, we could call {\tt Final} to get the hash of the entire message.
This proved to be effective and allowed us to hash larger messages than without previous monolithic function.

\subsection*{Echo}

As part of the submissions materials to the NIST competition the ECHO team submitted a 32 bit optimized version, a 64-bit optimized version and a reference implementation.  
We chose to base our OpenCL implementation on the reference implementation, hoping that it would be the most likely to work with little modification.
As it turned out the Echo function required a good deal of work to get to work.
We began the debugging process by flattening all the functions into the kernel to avoid any issues with pointer passing causing data to not be written back to the global buffers.
After having done this however, we still did not have a functional hash function - at least it was functional on the cpu but not the GPU.  
We at first did not have any idea how to resolve this issue - since it is very difficult to debug code that cannot contain any print statements and cannot write out to a file. 
Eventually, we began debugging by setting the return value of the hash to the memory that we wanted to look at, and began comparing the results from code that ran on teh CPU to the same code running on the GPU.
By doing this we found a number of small errors in the code.

Finally, the largest problem turned out to the be the accessible scope of the S-box.
Since the S-box was declared in the same file as the kernel we had assumed that it would be in the scope of the kernel and it would be stored in the local memory of the graphics card.
As it turned out by declaring the S-box outside of the actual kernel it was not instantiating the S-box in the local memory of the graphics card and instead when we tried to access the values of the S-box we only got 0's back.
It was particularly difficult to spot the error because the program behaved differently on the CPU and GPU - on the CPU it accessed the S-boxes as normal, but the GPU was unable to do the same until they were moved into the kernel.

\subsection*{Skein}

For Skein, we took their submitted reference implementation and modified it to work on the OpenCL framework.
Skein has perhaps the ``ugliest'' implementation out of all the algorithms we chose primarily because it is heavily optimized.
In fact, Skein has several different implementations depending on the required internal state: 256, 512, 1024 bits.
Because we decided to limit our hash lengths to 512-bits it made sense to use the 512-bit implementation.

The primary difficult in getting Skein running had to due with it's internal representation of the state.
Unlike most of the other algorithms, Skein chose to optimize for 64-bit systems and therefore all words are 64-bit.
On the face of things this doesn't seem like a bad decision considering the current migration to 64-bit is well underway.
However, we encountered a peculiarity in the way OpenCL works on the graphics cards we were testing.
In particular, it was difficult to get a 64-bit {\tt Rotate} operation working since the OpenCL provided function {\tt rotate} did not want to compile when the rotation was greater than 54.
We are unsure of the reason for this but we needed a workaround.
We ended up rewriting the {\tt Rotate} function to decompose the 64-bit words into 2 32-bit words and rotate these individually take care to account for overflow and such.
The solution is quite simple but we wasted a considerably amount of time working on this platform bug.
